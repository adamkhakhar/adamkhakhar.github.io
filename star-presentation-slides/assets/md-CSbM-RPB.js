import{b as s,o as a,w as o,g as l,aa as n,v as r,x as p,C as e}from"./modules/vue-BYOt8lIF.js";import{I as c}from"./slidev/default-BxkqrAHv.js";import{u as m,f as d}from"./slidev/context-DRYUuKN-.js";import"./index-Bdy7Wusa.js";import"./modules/shiki-DvFkKVjC.js";const C={__name:"slides.md__slidev_16",setup(f){const{$clicksContext:i,$frontmatter:u}=m();return i.setup(),(g,t)=>(a(),s(c,r(p(e(d)(e(u),15))),{default:o(()=>[...t[0]||(t[0]=[l("h1",null,"Key Takeaways",-1),l("div",{class:"grid grid-cols-2 gap-4 text-sm"},[l("div",null,[l("p",null,[l("strong",null,"What STaR Achieves")]),l("p",null,[n("✓ "),l("strong",null,"Scale-Equivalent Performance")]),l("ul",null,[l("li",null,"6B + STaR ≈ 175B direct fine-tuning")]),l("p",null,[n("✓ "),l("strong",null,"Data Efficiency")]),l("ul",null,[l("li",null,"Better results with less data: 10 examples → thousands of rationales")]),l("p",null,[n("✓ "),l("strong",null,"Generalization")]),l("ul",null,[l("li",null,"Out-of-distribution success"),l("li",null,"Novel solution discovery"),l("li",null,"Cross-difficulty learning")]),l("p",null,[n("✓ "),l("strong",null,"Human-Preferred Reasoning")]),l("ul",null,[l("li",null,"30% better than few-shot"),l("li",null,"74% better than human baselines")])]),l("div",null,[l("p",null,[l("strong",null,"Limitations & Future Work")]),l("p",null,[l("strong",null,"Current Constraints"),n(":")]),l("ul",null,[l("li",null,"Minimum model size (GPT-J viable, GPT-2 fails)"),l("li",null,"High baseline tasks problematic"),l("li",null,"Computational cost of iterations")]),l("p",null,[l("strong",null,"Open Questions"),n(":")]),l("ul",null,[l("li",null,"Optimal hint design"),l("li",null,"Application without ground truth"),l("li",null,"Faithfulness guarantees"),l("li",null,"Bias amplification risks")]),l("p",null,[l("strong",null,"Core Principle"),n(":")]),l("blockquote",null,[l("p",null,'"A model that can reason about its failures can learn to overcome them"')])])],-1)])]),_:1},16))}};export{C as default};
