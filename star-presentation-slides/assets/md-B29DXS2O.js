import{b as o,o as r,w as s,g as e,v as i,x as u,C as n}from"./modules/vue-BYOt8lIF.js";import{I as p}from"./slidev/default-BxkqrAHv.js";import{u as m,f as d}from"./slidev/context-DRYUuKN-.js";import"./index-Bdy7Wusa.js";import"./modules/shiki-DvFkKVjC.js";const x={__name:"slides.md__slidev_4",setup(c){const{$clicksContext:a,$frontmatter:l}=m();return a.setup(),(f,t)=>(r(),o(p,i(u(n(d)(n(l),3))),{default:s(()=>[...t[0]||(t[0]=[e("h1",null,"Core Insight and Contribution",-1),e("p",null,[e("strong",null,"Key Question: Can models generate their own training data?")],-1),e("p",null,[e("strong",null,"The STaR Insight")],-1),e("ul",null,[e("li",null,"Models already have latent reasoning capabilities"),e("li",null,"We can bootstrap: use few examples → generate many rationales → improve model → repeat"),e("li",null,"Self-improvement loop: better rationales → better training data → better model")],-1),e("p",null,[e("strong",null,"Paper’s Achievement")],-1),e("ul",null,[e("li",null,"GPT-J (6B) + STaR achieves 72.5% vs GPT-3 (175B) at 73.0% on CommonsenseQA"),e("li",null,"Using only 10 initial examples, generate training data for 86.7% of 9,741 problems"),e("li",null,'"STaR improves over both a few-shot baseline (+35.9%) and a baseline fine-tuned to directly predict answers (+12.5%)"')],-1)])]),_:1},16))}};export{x as default};
