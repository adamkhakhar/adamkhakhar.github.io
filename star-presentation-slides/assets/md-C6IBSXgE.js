import{b as i,o as r,w as l,g as e,v as s,x as u,C as n}from"./modules/vue-BYOt8lIF.js";import{I as c}from"./slidev/default-BxkqrAHv.js";import{u as m,f as p}from"./slidev/context-DRYUuKN-.js";import"./index-Bdy7Wusa.js";import"./modules/shiki-DvFkKVjC.js";const _={__name:"slides.md__slidev_2",setup(f){const{$clicksContext:a,$frontmatter:o}=m();return a.setup(),(h,t)=>(r(),i(c,s(u(n(p)(n(o),1))),{default:l(()=>[...t[0]||(t[0]=[e("h1",null,"The Power of Chain-of-Thought Reasoning",-1),e("p",null,[e("strong",null,"Chain-of-Thought (CoT) Prompting Revolution")],-1),e("ul",null,[e("li",null,"LLMs show dramatic improvements when generating explicit intermediate reasoning steps before final answers"),e("li",null,"Scratchpad methods achieve perfect in-distribution performance on arithmetic, while direct prediction fails (Nye et al., 2021 [5])"),e("li",null,"Few-shot CoT improves mathematical reasoning from <1% to substantive accuracy (Wei et al., 2022 [6])"),e("li",null,"Proven effective across domains: arithmetic, commonsense reasoning, code evaluation, social bias inference (Rajani et al., 2019 [3]; Wei et al., 2022 [6])")],-1),e("p",null,[e("strong",null,"The Fundamental Challenge")],-1),e("ul",null,[e("li",null,'CoT requires rationales ("step-by-step reasoning") in training or prompting'),e("li",null,"But where do we get these rationales at scale?")],-1)])]),_:1},16))}};export{_ as default};
